{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3da7cfb7",
   "metadata": {},
   "source": [
    "### HybridSPEA2GWOABC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8aa093d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import warnings\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import random\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "def feature_evaluation(selected_columns, data, target, complexity_weight=1):\n",
    "    X = data[selected_columns]\n",
    "    y = target\n",
    "    clf = GaussianNB()   # Using Random Forest classifier\n",
    "\n",
    "    # Use StratifiedKFold for cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_scores = cross_val_score(clf, X, y, cv=skf)\n",
    "\n",
    "    accuracy = np.mean(cv_scores)\n",
    "    robustness = np.std(cv_scores)\n",
    "\n",
    "    num_features = len(selected_columns)\n",
    "    complexity = complexity_weight / num_features if num_features > 0 else float('inf')\n",
    "    interpretability = complexity\n",
    "    return (accuracy, robustness, complexity, interpretability)\n",
    "\n",
    "\n",
    "def feature_evaluation_with_complexity_weight(selected_columns, data, target, complexity_weight):\n",
    "    # Adjusts feature evaluation to give more importance to complexity\n",
    "    accuracy, robustness, complexity, interpretability = feature_evaluation(selected_columns, data, target)\n",
    "    weighted_complexity_score = complexity_weight * complexity\n",
    "    return (accuracy, -robustness, weighted_complexity_score, interpretability)\n",
    "\n",
    "# Fitness Function\n",
    "def _fitness(individual, data, target, complexity_weight=0.3):\n",
    "    selected_features = data.columns[individual == 1]\n",
    "    return feature_evaluation(selected_features, data, target, complexity_weight)\n",
    "\n",
    "def update_archive(archive, population, fitness, archive_size):\n",
    "    # Combine the current archive and the new population\n",
    "    combined = np.vstack((archive, population))\n",
    "    combined_fitness = np.hstack((spea2_fitness_assignment(archive, data, target),\n",
    "                                  spea2_fitness_assignment(population, data, target)))\n",
    "\n",
    "    # Sort the combined array based on the fitness values\n",
    "    sorted_indices = np.argsort(combined_fitness)\n",
    "    updated_archive = combined[sorted_indices]\n",
    "\n",
    "    # Keep only the top individuals up to the specified archive size\n",
    "    if len(updated_archive) > archive_size:\n",
    "        updated_archive = updated_archive[:archive_size]\n",
    "\n",
    "    return updated_archive\n",
    "\n",
    "\n",
    "\n",
    "# Grey Wolf Optimizer (GWO) Phase\n",
    "def gwo_feature_evaluation(population, data, target, current_iter, max_iter):\n",
    "    alpha, beta, delta = _find_leaders(population, data, target)\n",
    "    a = 2 - 2 * (current_iter / max_iter)  \n",
    "\n",
    "    for i in range(len(population)):\n",
    "        wolf = population[i]\n",
    "        for j in range(len(wolf)):\n",
    "            r1, r2, r3 = np.random.rand(3)\n",
    "            A1 = 2 * a * r1 - a\n",
    "            C1 = 2 * r2\n",
    "            D_alpha = abs(C1 * alpha[j] - wolf[j])\n",
    "            X1 = alpha[j] - A1 * D_alpha\n",
    "\n",
    "            A2 = 2 * a * r3 - a\n",
    "            C2 = 2 * r2\n",
    "            D_beta = abs(C2 * beta[j] - wolf[j])\n",
    "            X2 = beta[j] - A2 * D_beta\n",
    "\n",
    "            A3 = 2 * a * r1 - a\n",
    "            C3 = 2 * r2\n",
    "            D_delta = abs(C3 * delta[j] - wolf[j])\n",
    "            X3 = delta[j] - A3 * D_delta\n",
    "\n",
    "            new_position = (X1 + X2 + X3) / 3\n",
    "            population[i][j] = 1 if new_position > 0.5 else 0\n",
    "\n",
    "# Find Leaders for GWO\n",
    "def _find_leaders(population, data, target):\n",
    "    fitness_values = np.array([_fitness(individual, data, target) for individual in population])\n",
    "    sorted_indices = np.argsort(fitness_values[:, 0])[::-1]  # Sort based on accuracy\n",
    "    alpha = population[sorted_indices[0]]\n",
    "    beta = population[sorted_indices[1]]\n",
    "    delta = population[sorted_indices[2]]\n",
    "    return alpha, beta, delta\n",
    "\n",
    "# SPEA2 Fitness Assignment\n",
    "def spea2_fitness_assignment(population, data, target):\n",
    "    fitness_values = np.array([feature_evaluation(data.columns[individual == 1], data, target) for individual in population])\n",
    "    domination_counts = np.zeros(len(fitness_values))\n",
    "    dominated_solutions = [[] for _ in range(len(fitness_values))]\n",
    "    strength = np.zeros(len(fitness_values))\n",
    "    raw_fitness = np.zeros(len(fitness_values))\n",
    "\n",
    "    for i in range(len(fitness_values)):\n",
    "        for j in range(len(fitness_values)):\n",
    "            if dominates(fitness_values[i], fitness_values[j]):\n",
    "                dominated_solutions[i].append(j)\n",
    "            elif dominates(fitness_values[j], fitness_values[i]):\n",
    "                domination_counts[i] += 1\n",
    "\n",
    "        strength[i] = len(dominated_solutions[i])\n",
    "        raw_fitness[i] = sum(strength[j] for j in dominated_solutions[i])\n",
    "\n",
    "    density = crowding_distance(fitness_values, calculate_non_dominated_ranks(fitness_values))\n",
    "    fitness = raw_fitness + 1.0 / (2.0 + density)\n",
    "\n",
    "    return fitness\n",
    "\n",
    "# SPEA2 Environmental Selection\n",
    "def spea2_environmental_selection(population, fitness, archive_size):\n",
    "    sorted_indices = np.argsort(fitness)\n",
    "    return population[sorted_indices][:archive_size]\n",
    "\n",
    "# Artificial Bee Colony (ABC) Phase\n",
    "def abc_feature_selection(archive, data, target):\n",
    "    for i in range(len(archive)):\n",
    "        solution = archive[i]\n",
    "\n",
    "        # Employed and Onlooker Bees Phases\n",
    "        for phase in ['employed', 'onlooker']:\n",
    "            if phase == 'onlooker':\n",
    "                # Calculate probabilities for onlooker bees\n",
    "                fitness_values = [feature_evaluation(data.columns[sol == 1], data, target)[0] for sol in archive]\n",
    "                prob = [f / sum(fitness_values) for f in fitness_values]\n",
    "                if np.random.rand() >= prob[i]:\n",
    "                    continue\n",
    "\n",
    "            phi = np.random.uniform(-1, 1, size=len(solution))\n",
    "            k = np.random.choice(len(archive))\n",
    "            while k == i:\n",
    "                k = np.random.choice(len(archive))\n",
    "            v = solution + phi * (solution - archive[k])\n",
    "\n",
    "            if feature_evaluation(data.columns[v == 1], data, target) > feature_evaluation(data.columns[solution == 1], data, target):\n",
    "                archive[i] = v\n",
    "\n",
    "        # Scout Bees Phase\n",
    "        if np.random.rand() < 0.1:  # Scout bee probability\n",
    "            archive[i] = np.random.randint(0, 2, len(solution))\n",
    "\n",
    "\n",
    "# Additional SPEA2 functions: Dominates, Non-Dominated Ranks, Crowding Distance\n",
    "def dominates(row, candidate_row):\n",
    "    return all(r >= c for r, c in zip(row, candidate_row)) and any(r > c for r, c in zip(row, candidate_row))\n",
    "\n",
    "def calculate_non_dominated_ranks(fitness_values):\n",
    "    domination_counts = np.zeros(len(fitness_values))\n",
    "    dominated_solutions = [[] for _ in range(len(fitness_values))]\n",
    "    ranks = np.zeros(len(fitness_values))\n",
    "\n",
    "    for i, row in enumerate(fitness_values):\n",
    "        for j, candidate_row in enumerate(fitness_values):\n",
    "            if dominates(row, candidate_row):\n",
    "                dominated_solutions[i].append(j)\n",
    "            elif dominates(candidate_row, row):\n",
    "                domination_counts[i] += 1\n",
    "\n",
    "        if domination_counts[i] == 0:\n",
    "            ranks[i] = 1\n",
    "\n",
    "    current_rank = 1\n",
    "    while sum(ranks == current_rank) > 0:\n",
    "        for i in range(len(fitness_values)):\n",
    "            if ranks[i] == current_rank:\n",
    "                for j in dominated_solutions[i]:\n",
    "                    domination_counts[j] -= 1\n",
    "                    if domination_counts[j] == 0:\n",
    "                        ranks[j] = current_rank + 1\n",
    "        current_rank += 1\n",
    "\n",
    "    return ranks\n",
    "\n",
    "def crowding_distance(fitness_values, ranks):\n",
    "    distances = np.zeros(len(fitness_values))\n",
    "    for rank in np.unique(ranks):\n",
    "        indices = np.where(ranks == rank)[0]\n",
    "        if len(indices) == 0: continue\n",
    "        rank_fitness_values = fitness_values[indices]\n",
    "        sorted_indices = np.argsort(rank_fitness_values, axis=0)\n",
    "        \n",
    "        norm = np.max(rank_fitness_values, axis=0) - np.min(rank_fitness_values, axis=0)\n",
    "        if np.any(norm == 0): norm[norm == 0] = 1  # Avoid division by zero\n",
    "\n",
    "        distances[indices[sorted_indices[0, :]]] = np.inf\n",
    "        distances[indices[sorted_indices[-1, :]]] = np.inf\n",
    "\n",
    "        for i in range(1, len(indices) - 1):\n",
    "            for j in range(rank_fitness_values.shape[1]):\n",
    "                distances[indices[i]] += (rank_fitness_values[sorted_indices[i + 1, j], j] - rank_fitness_values[sorted_indices[i - 1, j], j]) / norm[j]\n",
    "\n",
    "    return distances\n",
    "\n",
    "\n",
    "\n",
    "def spea2_binary_tournament_selection(fitness, population_size):\n",
    "    selected_indices = []\n",
    "    for _ in range(population_size):\n",
    "        candidate1 = random.randint(0, len(fitness) - 1)\n",
    "        candidate2 = random.randint(0, len(fitness) - 1)\n",
    "        while candidate2 == candidate1:  # Ensure different candidates\n",
    "            candidate2 = random.randint(0, len(fitness) - 1)\n",
    "        if fitness[candidate1] <= fitness[candidate2]:\n",
    "            selected_indices.append(candidate1)\n",
    "        else:\n",
    "            selected_indices.append(candidate2)\n",
    "    return selected_indices\n",
    "\n",
    "def spea2_crossover(selected_population):\n",
    "    num_parents = len(selected_population)\n",
    "    num_offspring = len(selected_population)\n",
    "    offspring = []\n",
    "    \n",
    "    for i in range(num_offspring):\n",
    "        parent1 = selected_population[i % num_parents]\n",
    "        parent2 = selected_population[(i + 1) % num_parents]\n",
    "        crossover_point = random.randint(1, len(parent1) - 1)\n",
    "        child = np.concatenate((parent1[:crossover_point], parent2[crossover_point:]))\n",
    "        offspring.append(child)\n",
    "    \n",
    "    return offspring\n",
    "\n",
    "def spea2_mutation(offspring, mutation_rate=0.1):\n",
    "    mutated_offspring = []\n",
    "    for individual in offspring:\n",
    "        mutated_individual = individual.copy()\n",
    "        for i in range(len(mutated_individual)):\n",
    "            if random.random() < mutation_rate:\n",
    "                mutated_individual[i] = 1 - mutated_individual[i]  # Flip the bit\n",
    "        mutated_offspring.append(mutated_individual)\n",
    "    return mutated_offspring\n",
    "\n",
    "def replace_worst_individuals(population, fitness, mutated_offspring):\n",
    "    # Combine original population and mutated offspring\n",
    "    combined_population = np.vstack((population, mutated_offspring))\n",
    "\n",
    "    # Sort combined population by fitness in ascending order\n",
    "    sorted_indices = np.argsort(fitness)\n",
    "    sorted_population = combined_population[sorted_indices]\n",
    "\n",
    "    # Replace the worst individuals in the original population with the mutated offspring\n",
    "    population[:len(mutated_offspring)] = sorted_population[:len(mutated_offspring)]\n",
    "\n",
    "    return population\n",
    "\n",
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load or define your data and target here\n",
    "    data = df.drop(\"type\", axis=1)\n",
    "    target = df[\"type\"]\n",
    "    \n",
    "    # Normalize the data using MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "    data_normalized = scaler.fit_transform(data)\n",
    "    data_normalized = pd.DataFrame(data_normalized, columns=data.columns)\n",
    "\n",
    "    # Splitting the normalized data\n",
    "    data_train, data_val, target_train, target_val = train_test_split(\n",
    "        data_normalized, target, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # Setting up parameters for optimization\n",
    "    population_size = 500\n",
    "    archive_size = 300\n",
    "    num_features = data_train.shape[1]\n",
    "    max_iter = 20\n",
    "    complexity_weight = 0.3  # Adjust as needed\n",
    "\n",
    "    # Initialize metrics monitoring\n",
    "    accuracy_history = []\n",
    "    complexity_history = []\n",
    "    \n",
    "    # Initialize population and archive for feature selection algorithms\n",
    "    population = np.random.randint(0, 2, (population_size, num_features))\n",
    "    archive = None  # Initialize an empty archive\n",
    "    \n",
    "    # Initialize variables to store the best results\n",
    "    best_accuracy = 0\n",
    "    best_robustness = float('inf')  # Assuming lower robustness is better\n",
    "    best_complexity = float('inf')  # Assuming lower complexity is better\n",
    "    best_weighted_complexity_score = float('inf')\n",
    "    best_features = []\n",
    "    best_interpretability = float('inf') \n",
    "\n",
    "    # Initialize early stopping parameters\n",
    "    delta = 0.001  # Minimum change in the monitored quantity to qualify as an improvement\n",
    "    patience = 5  # Number of iterations with no improvement before stopping\n",
    "    patience_counter = 0\n",
    "  \n",
    "    # Optimization loop\n",
    "    for current_iter in tqdm(range(max_iter), desc=\"Optimizing Hybrid_SPEA2GWOABC\", unit=\"iteration\"):\n",
    "        # Grey Wolf Optimizer (GWO) Phase\n",
    "        gwo_feature_evaluation(population, data_train, target_train, current_iter, max_iter)\n",
    "\n",
    "        # SPEA2 Fitness Assignment\n",
    "        fitness = spea2_fitness_assignment(population, data_train, target_train)\n",
    "\n",
    "        # SPEA2 Environmental Selection\n",
    "        if archive is None:\n",
    "            archive = spea2_environmental_selection(population, fitness, archive_size)\n",
    "        else:\n",
    "            archive = update_archive(archive, population, fitness, archive_size)\n",
    "\n",
    "        # SPEA2 Binary Tournament Selection\n",
    "        selected_indices = spea2_binary_tournament_selection(fitness, population_size)\n",
    "        selected_population = population[selected_indices]\n",
    "\n",
    "        # SPEA2 Crossover\n",
    "        offspring = spea2_crossover(selected_population)\n",
    "\n",
    "        # SPEA2 Mutation\n",
    "        mutated_offspring = spea2_mutation(offspring)\n",
    "\n",
    "        # Replace the worst individuals in the population with the mutated offspring\n",
    "        population = replace_worst_individuals(population, fitness, mutated_offspring)\n",
    "\n",
    "        # Artificial Bee Colony (ABC) Phase\n",
    "        abc_feature_selection(archive, data_train, target_train)\n",
    "\n",
    "        # Evaluate on the full archive to find the best features\n",
    "        accuracy, robustness, complexity, interpretability = feature_evaluation(data_train.columns[np.argsort(np.sum(archive, axis=0))], data_val, target_val)\n",
    "        best_features_from_archive = data_train.columns[np.argsort(np.sum(archive, axis=0))][-100:]  # Select top 100 features from the archive\n",
    "\n",
    "        # Evaluate on the subset of the validation set to monitor performance\n",
    "        accuracy, robustness, complexity, interpretability = feature_evaluation(best_features_from_archive, data_val, target_val)\n",
    "\n",
    "        # Check for improvement in any metric\n",
    "        is_improved = False\n",
    "        if accuracy > best_accuracy + delta:\n",
    "            best_accuracy = accuracy\n",
    "            is_improved = True\n",
    "        if robustness < best_robustness and robustness != float('inf'):  # Ensure robustness is meaningful\n",
    "            best_robustness = robustness\n",
    "            is_improved = True\n",
    "        if complexity < best_complexity and complexity != float('inf'):  # Ensure complexity is meaningful\n",
    "            best_complexity = complexity\n",
    "            is_improved = True\n",
    "        if complexity_weight * complexity < best_weighted_complexity_score and complexity != float('inf'):  # Ensure weighted complexity is meaningful\n",
    "            best_weighted_complexity_score = complexity_weight * complexity\n",
    "            is_improved = True\n",
    "\n",
    "        # If any metric is improved, update the best features\n",
    "        if is_improved:\n",
    "            best_features = best_features_from_archive.copy()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        # Early stopping condition\n",
    "        if patience_counter > patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "        # Update best interpretability score\n",
    "        if complexity == float('inf'):\n",
    "            interpretability = float('inf')  # Set interpretability to a large finite value if no features are selected\n",
    "        if interpretability < best_interpretability:\n",
    "            best_interpretability = interpretability\n",
    "        \n",
    "        # Append metrics to history for plotting\n",
    "        accuracy_history.append(accuracy)\n",
    "        complexity_history.append(complexity)\n",
    "   \n",
    "    # Adjust the range to match the length of the accuracy_history\n",
    "    iterations_completed = len(accuracy_history)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Plot for Accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(iterations_completed), accuracy_history, label='Accuracy')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy over Iterations')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot for Complexity (adjust similarly if complexity_history is used)\n",
    "    # Ensure complexity_history is updated in each iteration\n",
    "    if len(complexity_history) == iterations_completed:\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(range(iterations_completed), complexity_history, label='Complexity')\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Complexity')\n",
    "        plt.title('Complexity over Iterations')\n",
    "        plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Extracting top features after the optimization loop\n",
    "    top_n = 100  # Define how many top features you want to consider\n",
    "    feature_counts = np.sum(archive, axis=0)\n",
    "    top_features_indices = np.argsort(feature_counts)[-top_n:]\n",
    "    top_features = data_train.columns[top_features_indices]\n",
    "\n",
    "    # Evaluate the performance on the validation set using the selected top features\n",
    "    accuracy, robustness, complexity, interpretability = feature_evaluation(top_features, data_val, target_val)\n",
    "    \n",
    "    # Update best scores and features if current ones are better\n",
    "    # Inside the optimization loop\n",
    "    if accuracy > best_accuracy + delta:\n",
    "        best_accuracy = accuracy\n",
    "        best_robustness = robustness\n",
    "        best_complexity = complexity\n",
    "        best_interpretability = interpretability\n",
    "        best_features = subset_top_features.copy()  # Update the best features\n",
    "        patience_counter = 0  # Reset counter\n",
    "    else:\n",
    "        patience_counter += 1  # Increment counter\n",
    "\n",
    "    print(f\"##############################################################################\")\n",
    "    # Print the best results after the optimization loop\n",
    "    print(\"\\nBest Results:\")\n",
    "    print(f\"Best Accuracy: {best_accuracy}\")\n",
    "    print(f\"Best Robustness: {best_robustness}\")\n",
    "    print(f\"Best Complexity: {best_complexity}\")\n",
    "    print(f\"Best Weighted Complexity Score: {best_weighted_complexity_score}\")\n",
    "\n",
    "    print(f\"##############################################################################\")\n",
    "    \n",
    "    # Display best results after optimization loop\n",
    "    print(f\"Best Validation Accuracy with top {top_n} features: {best_accuracy:.4f}\")\n",
    "    print(f\"Best Validation Robustness (Std Dev of CV scores): {best_robustness:.4f}\")\n",
    "    print(f\"Best Complexity (1/Number of Features): {best_complexity:.4f}\")\n",
    "    print(f\"Best Interpretability (Same as Complexity here): {best_interpretability:.4f}\")\n",
    "    \n",
    "    print(f\"##############################################################################\")\n",
    "    # Print the selected top features for the best result\n",
    "    # End of optimization loop\n",
    "    if not best_features.empty:\n",
    "        print(\"\\nSelected top features for the best result:\")\n",
    "        for feature in best_features:\n",
    "            print(feature)\n",
    "    else:\n",
    "        print(\"No best features were selected.\")\n",
    "\n",
    "    print(f\"##############################################################################\")    \n",
    "        \n",
    "    top_features = data_train.columns[:100]  \n",
    "    clf = NearestCentroid()  \n",
    "    clf.fit(data_train[top_features], target_train)\n",
    "\n",
    "    # Predict on the validation set\n",
    "    predictions = clf.predict(data_val[top_features])\n",
    "\n",
    "    # Calculate the confusion matrix\n",
    "    conf_matrix = confusion_matrix(target_val, predictions)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='g', cmap='viridis')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('Actual Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "    print(f\"##############################################################################\")\n",
    "\n",
    "    # Calculate classification report for more metrics\n",
    "    class_report = classification_report(target_val, predictions)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(class_report)\n",
    "    print(f\"##############################################################################\")    \n",
    "    # Sensitivity Analysis with Selected Top Features\n",
    "    sensitivity_results = {}\n",
    "    for feature in top_features:\n",
    "        temp_features = [f for f in top_features if f != feature]  # Exclude the current feature\n",
    "        clf.fit(data_train[temp_features], target_train)\n",
    "        temp_predictions = clf.predict(data_val[temp_features])\n",
    "        temp_accuracy = np.mean(temp_predictions == target_val)\n",
    "        sensitivity_results[feature] = temp_accuracy\n",
    "    print(f\"##############################################################################\")\n",
    "    # Print the sensitivity analysis results\n",
    "    print(\"\\nSensitivity Analysis (Impact of leaving out each feature):\")\n",
    "    for feature, accuracy in sensitivity_results.items():\n",
    "        print(f\"{feature}: {accuracy:.4f}\")\n",
    "    \n",
    "    #  'sensitivity_results' is a dictionary\n",
    "    features = list(sensitivity_results.keys())\n",
    "    accuracies = list(sensitivity_results.values())\n",
    "\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.bar(features, accuracies, color='skyblue')\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Sensitivity Analysis')\n",
    "    plt.xticks(rotation=90)  # Rotates the feature names for better readability\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ff3602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7670b98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d7d179",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (ml)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
